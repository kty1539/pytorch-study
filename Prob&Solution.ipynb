{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Weight_Regularization\n",
        "torch.optim.SGD(params, lr=1, momentum=0, dampening=0, weight_decay=0, nesterov=False)"
      ],
      "metadata": {
        "id": "01nhdMNAKKP6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xpMWIea8KHRf"
      },
      "outputs": [],
      "source": [
        "# 모듈 임포트\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 설정\n",
        "batch_size = 16\n",
        "learning_rate = 0.0002\n",
        "num_epoch = 1\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "FUqbr0fIKaWI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드\n",
        "mnist_train = dsets.MNIST(root='./', train=True, transform=transforms.ToTensor(), download=True)\n",
        "mnist_test = dsets.MNIST(root='./', train=False, transform=transforms.ToTensor(), download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4m8KkhCKd8p",
        "outputId": "8cbfb458-bfe9-4f01-c322-d2e4b92e9296"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:02<00:00, 4.59MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 58.6kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.27MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 10.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 체크\n",
        "print(mnist_train[0][0].size(), len(mnist_train))\n",
        "print(mnist_test[0][0].size(), len(mnist_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnuuHI45KphE",
        "outputId": "8022148c-1899-4c09-e78c-14cb11e66e58"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28]) 60000\n",
            "torch.Size([1, 28, 28]) 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터로더 설정\n",
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=2, drop_last=True)"
      ],
      "metadata": {
        "id": "bAnZ1DUxK4Pe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN 모델\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    self.layer = nn.Sequential(\n",
        "        nn.Conv2d(1, 16, 3, padding=1), # 28\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(16, 32, 3, padding=1), # 28\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2), # 14\n",
        "        nn.Conv2d(32, 64, 3, padding=1), # 14\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2) # 7\n",
        "    )\n",
        "    self.fc_layer = nn.Sequential(\n",
        "        nn.Linear(64 * 7 * 7, 100),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(100, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.layer(x)\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = self.fc_layer(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "model = CNN().to(device)"
      ],
      "metadata": {
        "id": "jiLDwSqpLTPS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실 함수 및 옵티마이저\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=0.1) # L2 규제 적용"
      ],
      "metadata": {
        "id": "HGU2_02WL7gc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "total_batch = len(train_loader)\n",
        "for epoch in range(num_epoch):\n",
        "  avg_cost = 0\n",
        "  for X, Y in train_loader:\n",
        "    X = X.to(device)\n",
        "    Y = Y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X)\n",
        "    cost = criterion(output, Y)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    avg_cost += cost / total_batch\n",
        "\n",
        "  print('[Epoch {}] Cost : {}'.format(epoch + 1, avg_cost))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ciq377wME89",
        "outputId": "014bc760-de00-490b-9461-ddb027d2f3df"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1] Cost : 2.2979650497436523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트\n",
        "with torch.no_grad():\n",
        "  X = mnist_test.data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
        "  Y = mnist_test.targets.to(device)\n",
        "\n",
        "  output = model(X)\n",
        "  prediction = torch.argmax(output, dim=1) == Y\n",
        "  correct_prediction = prediction.float().sum()\n",
        "\n",
        "print('정확도 : {}'.format(100 * correct_prediction / len(mnist_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCYOvACEMhRg",
        "outputId": "caab5416-d76f-4628-cdc9-67e287d2668e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도 : 18.68000030517578\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dropout\n",
        "nn.Dropout(p=0.5, inplace=False)"
      ],
      "metadata": {
        "id": "friTnw8EN141"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모듈 임포트\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "TJc6TeQ0NMwN"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 설정\n",
        "batch_size = 16\n",
        "learning_rate = 0.0002\n",
        "num_epoch = 1"
      ],
      "metadata": {
        "id": "ZTumnmlEOgkB"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터\n",
        "mnist_train = dsets.MNIST('./', train=True, transform=transforms.ToTensor(), download=True)\n",
        "mnist_test = dsets.MNIST('./', train=False, transform=transforms.ToTensor(), download=True)"
      ],
      "metadata": {
        "id": "sOEMYi3lOkn-"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터로더 설정\n",
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)"
      ],
      "metadata": {
        "id": "ZabNW3m5Ov1m"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 설정\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    self.layer = nn.Sequential(\n",
        "        nn.Conv2d(1, 16, 3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout2d(0.2), 0.2는 드롭아웃 확률\n",
        "        nn.Conv2d(16, 32, 3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout2d(0.2),\n",
        "        nn.MaxPool2d(2, 2),\n",
        "        nn.Conv2d(32, 64, 3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout2d(0.2),\n",
        "        nn.MaxPool2d(2, 2)\n",
        "    )\n",
        "    self.fc_layer = nn.Sequential(\n",
        "        nn.Linear(64 * 7 * 7, 100),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(100, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.layer(x)\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = self.fc_layer(out)\n",
        "    return out\n",
        "\n",
        "model = CNN().to(device)"
      ],
      "metadata": {
        "id": "86NGPhLBO5qy"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실 함수 및 옵티마이저\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "90z_uBRyQEAV"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "total_batch = len(train_loader)\n",
        "for epoch in range(num_epoch):\n",
        "  avg_cost = 0\n",
        "  for X, Y in train_loader:\n",
        "    X = X.to(device)\n",
        "    Y = Y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X)\n",
        "    cost = criterion(output, Y)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    avg_cost += cost / total_batch\n",
        "\n",
        "  print('Epoch : {}, Cost : {}'.format(epoch + 1, avg_cost))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2C36W3CQs30",
        "outputId": "79f6e3af-d15d-4dcc-ba93-07edd1ea0fb2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1, Cost : 2.2964842319488525\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트\n",
        "model.eval() # 배치 정규화, 드롭아웃 등을 비활성화\n",
        "\n",
        "with torch.no_grad():\n",
        "  X = mnist_test.data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
        "  Y = mnist_test.targets.to(device)\n",
        "\n",
        "  output = model(X)\n",
        "  prediction = torch.argmax(output, dim=1) == Y\n",
        "  correct_prediction = prediction.float().sum()\n",
        "\n",
        "print('정확도 : {}'.format(100 * correct_prediction / len(mnist_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fynz9RGrRKDi",
        "outputId": "a33bb338-59f5-4e0e-c9c6-4e2680d521aa"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도 : 25.079999923706055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data_Augmentation\n",
        "- Resize\n",
        "- Crop\n",
        "- Flip\n",
        "- Rotate (using PIL Transform)"
      ],
      "metadata": {
        "id": "X5qqcyNuSVCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "LKB0CWWuRoTJ"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 설정\n",
        "batch_size = 16\n",
        "learning_rate = 0.0002\n",
        "num_epoch = 2"
      ],
      "metadata": {
        "id": "MK4llil9TVTj"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 다운로드\n",
        "mnist_train = dsets.MNIST('./', train=True,\n",
        "                          transform = transforms.Compose([\n",
        "                              transforms.Resize((34, 34)),\n",
        "                              transforms.CenterCrop(28),\n",
        "                              transforms.RandomHorizontalFlip(),\n",
        "                              transforms.ToTensor(),\n",
        "                          ]),\n",
        "                          download=True)\n",
        "mnist_test = dsets.MNIST('./', train=False, transform=transforms.ToTensor(), download=True)"
      ],
      "metadata": {
        "id": "MoLnY-Q4Tag0"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 확인\n",
        "print(mnist_train[0][0].size(), len(mnist_train))\n",
        "print(mnist_test[0][0].size(), len(mnist_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oDZXVH1TueP",
        "outputId": "8d5e590e-32db-43e2-fe21-b82df0483e6d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28]) 60000\n",
            "torch.Size([1, 28, 28]) 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터로더\n",
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)"
      ],
      "metadata": {
        "id": "7QigMbtiT4Zp"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN 모델\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    self.layer = nn.Sequential(\n",
        "        nn.Conv2d(1, 16, 3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(16,  32, 3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2),\n",
        "        nn.Conv2d(32, 64, 3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2)\n",
        "    )\n",
        "    self.fc_layer = nn.Sequential(\n",
        "        nn.Linear(64 * 7 * 7, 100),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(100, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.layer(x)\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = self.fc_layer(out)\n",
        "    return out\n",
        "\n",
        "model = CNN().to(device)"
      ],
      "metadata": {
        "id": "1Vv44TfhUD3P"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실함수 및 옵티마이저\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "QoXneCwrUp59"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습\n",
        "total_batch = len(train_loader)\n",
        "for epoch in range(num_epoch):\n",
        "  avg_cost = 0\n",
        "  for X, Y in train_loader:\n",
        "    X = X.to(device)\n",
        "    Y = Y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X)\n",
        "    cost = criterion(output, Y)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    avg_cost += cost / total_batch\n",
        "\n",
        "  print('Epoch : {}, Cost : {}'.format(epoch + 1, avg_cost))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ELwUkXlU0QP",
        "outputId": "67f032b7-31aa-41c2-d186-b16220ce6773"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1, Cost : 2.302511692047119\n",
            "Epoch : 2, Cost : 2.298917055130005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-bQCvpiVPyH",
        "outputId": "cc306e15-8209-46b1-8f69-3a3ceccc5c63"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3750"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트\n",
        "with torch.no_grad():\n",
        "  X = mnist_test.data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
        "  Y = mnist_test.targets.to(device)\n",
        "\n",
        "  output = model(X)\n",
        "  prediction = torch.argmax(output, dim=1) == Y\n",
        "  correct_prediction = prediction.float().sum()\n",
        "\n",
        "print('정확도 : {}'.format(100 * correct_prediction / len(mnist_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCllJJgWVQvE",
        "outputId": "dd55e7b9-fc05-43e1-9c9b-45407ddd090c"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도 : 26.349998474121094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weight Initialization\n",
        "- Initialize with small numbers\n",
        "- Xavier Initialization\n",
        "- Kaiming He Initialization"
      ],
      "metadata": {
        "id": "pu5zeqt0YUIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "9mK72UA3V4Ta"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 설정\n",
        "batch_size = 16\n",
        "learning_rate = 0.0002\n",
        "num_epoch = 1"
      ],
      "metadata": {
        "id": "GlHRnMAsZjAc"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train = dsets.MNIST(\"./\", train=True, transform=transforms.ToTensor(), download=True)\n",
        "mnist_test = dsets.MNIST(\"./\", train=False, transform=transforms.ToTensor(), download=True)"
      ],
      "metadata": {
        "id": "XEUpIWXBZm7n"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터로더 설정\n",
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)"
      ],
      "metadata": {
        "id": "j2DWw0DEZrHd"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN 모델\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    self.layer = nn.Sequential(\n",
        "        nn.Conv2d(1, 16, 3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(16, 32, 3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2),\n",
        "        nn.Conv2d(32, 64, 3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2)\n",
        "    )\n",
        "    self.fc_layer = nn.Sequential(\n",
        "        nn.Linear(64 * 7 * 7, 100),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(100, 10)\n",
        "    )\n",
        "\n",
        "    # initialization\n",
        "\n",
        "    for m in self.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "        '''# Init with small numbers\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "        # Xavier Initialization\n",
        "        init.xavier_normal(m.weight.data)\n",
        "        m.bias.data.fill_(0)'''\n",
        "\n",
        "        # Kaming Initialization\n",
        "        init.kaiming_normal_(m.weight)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "      elif isinstance(m, nn.Linear):\n",
        "        init.kaiming_normal_(m.weight)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.layer(x)\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = self.fc_layer(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "model = CNN().to(device)"
      ],
      "metadata": {
        "id": "dFZyBVuDZ4Oi"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실함수 및 옵티마이저\n",
        "loss_func = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "KJgURzphdIn0"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습\n",
        "total_batch = len(train_loader)\n",
        "for epoch in range(num_epoch):\n",
        "  avg_cost = 0\n",
        "  for X, Y in train_loader:\n",
        "    X = X.to(device)\n",
        "    Y = Y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X)\n",
        "    cost = loss_func(output, Y)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    avg_cost += cost / total_batch\n",
        "\n",
        "  print('Epoch : {}, Cost : {}'.format(epoch + 1, avg_cost))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zud76GZdkD6",
        "outputId": "53ffcd97-bdab-4e40-9715-907e2174978a"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1, Cost : 3.297081708908081\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습\n",
        "\n",
        "with torch.no_grad():\n",
        "  X = mnist_test.data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
        "  Y = mnist_test.targets.to(device)\n",
        "\n",
        "  output = model(X)\n",
        "  prediction = torch.argmax(output, dim=1) == Y\n",
        "  correct_prediction = prediction.float().sum()\n",
        "\n",
        "print('정확도 : {}'.format(100 * correct_prediction / len(mnist_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GH3USyHd-zN",
        "outputId": "26e27d67-d536-4833-b98e-0a51a0d3b38f"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도 : 15.289999961853027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning Rate Scheduler\n",
        "- optim.lr_scheduler.StepLR()\n",
        "- optim.lr_scheduler.MultiStepLR()\n",
        "- optim.lr_scheduler.ExponentialLR()\n",
        "- optim.lr_scheduler.ReduceLROnPlateau()"
      ],
      "metadata": {
        "id": "jFjCaMe9fuJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "VMLkkLzzfkA6"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼 파라미터\n",
        "batch_size = 16\n",
        "learning_rate = 0.001\n",
        "num_epoch = 2"
      ],
      "metadata": {
        "id": "CeNvVyG-gqFf"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터\n",
        "mnist_train = dsets.MNIST('./', train=True, transform=transforms.ToTensor(), download=True)\n",
        "mnist_test = dsets.MNIST('./', train=False, transform=transforms.ToTensor(), download=True)"
      ],
      "metadata": {
        "id": "jf7qmUPiguoa"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN 모델\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    self.layer = nn.Sequential(\n",
        "        nn.Conv2d(1, 16, 3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(16, 32, 3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2),\n",
        "        nn.Conv2d(32, 64, 3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2)\n",
        "    )\n",
        "    self.fc_layer = nn.Sequential(\n",
        "        nn.Linear(64*7*7, 100),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(100, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.layer(x)\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = self.fc_layer(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "model = CNN().to(device)"
      ],
      "metadata": {
        "id": "j4PTjSX7g8f_"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실 함수 및 옵티마이저\n",
        "loss_func = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.99)\n",
        "\n",
        "print(dir(scheduler))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9CEz0NXhduL",
        "outputId": "86f5868e-b770-469e-874a-4392ce55df05"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_get_closed_form_lr', '_get_lr_called_within_step', '_initial_step', '_last_lr', '_step_count', 'base_lrs', 'gamma', 'get_last_lr', 'get_lr', 'last_epoch', 'load_state_dict', 'optimizer', 'print_lr', 'state_dict', 'step', 'step_size', 'verbose']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습\n",
        "total_batch = len(train_loader)\n",
        "for epoch in range(num_epoch):\n",
        "  scheduler.step()\n",
        "  avg_cost = 0\n",
        "  #scheduler.step(loss.cpu().data.numpy()) # only for ReduceLRONPlateau\n",
        "  for X, Y in train_loader:\n",
        "    X = X.to(device)\n",
        "    Y = Y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X)\n",
        "    cost = loss_func(output, Y)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    avg_cost += cost / total_batch\n",
        "  print('Epoch : {}, lr : {}, Cost : {}'.format(epoch + 1, scheduler.get_lr(), avg_cost))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a14MJdtQhwjQ",
        "outputId": "5293bcf2-33b4-48c6-d72b-dd9b8e49a188"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1, lr : [0.000970299], Cost : 1.856903314590454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:536: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  _warn_get_lr_called_within_step(self)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 2, lr : [0.0009605960099999999], Cost : 0.3945898115634918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트\n",
        "with torch.no_grad():\n",
        "  X = mnist_test.data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
        "  Y = mnist_test.targets.to(device)\n",
        "\n",
        "  output = model(X)\n",
        "  prediction = torch.argmax(output, dim=1) == Y\n",
        "  correct_prediction = prediction.float().sum()\n",
        "\n",
        "print('정확도 : {}'.format(100 * correct_prediction / len(mnist_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dzDWj4ujxlG",
        "outputId": "970b03ec-919a-4bf1-bbb7-7054292a2aa3"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도 : 90.27999877929688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Normalization\n",
        "- Normalize MNIST Data"
      ],
      "metadata": {
        "id": "03FJDenGkVsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "6DUmd4n-kSwJ"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 설정\n",
        "batch_size = 16\n",
        "learning_rate = 0.0002\n",
        "num_epoch = 1"
      ],
      "metadata": {
        "id": "H8s4f-CjlVE1"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 다운로드\n",
        "# Normalize의 mean (R, G, B) 각 채널별로 평균 값을 주면 됨\n",
        "# ToTensor()만 거치면 0~1사이의 값으로 바뀜\n",
        "mnist_train = dsets.MNIST('./', train=True,\n",
        "                          transform=transforms.Compose([\n",
        "                              transforms.ToTensor(),\n",
        "                              transforms.Normalize(mean=(0.1307,), std=(0.3081,))\n",
        "                          ]),\n",
        "                          download=True)\n",
        "mnist_test = dsets.MNIST('./', train=False,\n",
        "                         transform=transforms.Compose([\n",
        "                             transforms.ToTensor(),\n",
        "                             transforms.Normalize(mean=(0.1307,), std=(0.3081,))\n",
        "                         ]),\n",
        "                         download=True)"
      ],
      "metadata": {
        "id": "oHgS9_splmsk"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch Normalization"
      ],
      "metadata": {
        "id": "Trtcnmdenckb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "_TF4FTeqmsts"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "learning_rate = 0.0002\n",
        "num_epoch = 1"
      ],
      "metadata": {
        "id": "Hq9RWM77n0gz"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train = dsets.MNIST(\"./\", train=True, transform=transforms.ToTensor(), download=True)\n",
        "mnist_test = dsets.MNIST(\"./\", train=False, transform=transforms.ToTensor(), download=True)"
      ],
      "metadata": {
        "id": "2ODQZMg4n1wY"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터로더\n",
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)"
      ],
      "metadata": {
        "id": "8w8qHmJzn7J0"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN 모델\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    self.layer = nn.Sequential(\n",
        "        nn.Conv2d(1, 16, 3, padding=1), # 28\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(16, 32, 3, padding=1), # 28\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2), # 14\n",
        "        nn.Conv2d(32, 64, 3, padding=1), # 14\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2) # 7\n",
        "    )\n",
        "    self.fc_layer = nn.Sequential(\n",
        "        nn.Linear(64 * 7 * 7, 100),\n",
        "        nn.BatchNorm1d(100),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(100, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.layer(x)\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = self.fc_layer(out)\n",
        "    return out\n",
        "\n",
        "model = CNN().to(device)"
      ],
      "metadata": {
        "id": "-lCsM0DNoDsv"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실 함수 및 optimizer\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "DskNHvGtp8OK"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "total_batch = len(train_loader)\n",
        "for epoch in range(5):\n",
        "  avg_cost = 0\n",
        "  for X, Y in train_loader:\n",
        "    X = X.to(device)\n",
        "    Y = Y.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X)\n",
        "    cost = criterion(output, Y)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    avg_cost += cost / total_batch\n",
        "  print('Epoch : {}, Cost : {}'.format(epoch + 1, avg_cost))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PODbOb8vrN0n",
        "outputId": "aebc6a76-9e23-4761-c6a3-df129a6f4dbb"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1, Cost : 2.3775434494018555\n",
            "Epoch : 2, Cost : 2.3775386810302734\n",
            "Epoch : 3, Cost : 2.377542734146118\n",
            "Epoch : 4, Cost : 2.3775405883789062\n",
            "Epoch : 5, Cost : 2.3775441646575928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트\n",
        "model.eval() # 배치정규화 층 비활성화\n",
        "\n",
        "with torch.no_grad():\n",
        "  X = mnist_test.data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
        "  Y = mnist_test.targets.to(device)\n",
        "\n",
        "  output = model(X)\n",
        "  prediction = torch.argmax(output, dim=1) == Y\n",
        "  correct_prediction = prediction.float().sum()\n",
        "\n",
        "print('정확도 : {}'.format(100 * correct_prediction / len(mnist_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dTv2NhZsCQN",
        "outputId": "7aba0b72-66e3-4f35-99e4-2e9e678b6b33"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도 : 8.880000114440918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Descent Variants\n",
        "- SGD\n",
        "- Momentum\n",
        "- Nestrov\n",
        "- Adagrad\n",
        "- Adadelta\n",
        "- Adam"
      ],
      "metadata": {
        "id": "OxtU3VKFt_1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "esBiyTastgmZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 설정\n",
        "batch_size = 16\n",
        "learning_rate = 0.0002\n",
        "num_epoch = 1"
      ],
      "metadata": {
        "id": "v3d826oHutmC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터\n",
        "mnist_train = dsets.MNIST('./', train=True, transform=transforms.ToTensor(), download=True)\n",
        "mnist_test = dsets.MNIST('./', train=False, transform=transforms.ToTensor(), download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AwbpR6gv1eR",
        "outputId": "805bb112-fafe-43e8-d662-6144b09dc4a7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.18MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 153kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.45MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.76MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터로더\n",
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=2, drop_last=True)"
      ],
      "metadata": {
        "id": "Y9Buz9lxwwUU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN 모델\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    self.layer = nn.Sequential(\n",
        "        nn.Conv2d(1, 16, 3, padding=1), # 28\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(16, 32, 3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2), # 14\n",
        "        nn.Conv2d(32, 64, 3, padding=1), # 14\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2) # 7\n",
        "    )\n",
        "    self.fc_layer = nn.Sequential(\n",
        "        nn.Linear(64 * 7 * 7, 100),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(100, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.layer(x)\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = self.fc_layer(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "model = CNN()"
      ],
      "metadata": {
        "id": "OoM52HNqw9Mm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실 함수 및 optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "5wHyOvMWxz9B"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습\n",
        "total_batch = len(train_loader)\n",
        "for epoch in range(num_epoch):\n",
        "  avg_cost = 0\n",
        "  for X, Y in train_loader:\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X)\n",
        "    cost = criterion(output, Y)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    avg_cost += cost / total_batch\n",
        "\n",
        "  print('[Epoch {}] Cost : {}'.format(epoch + 1, avg_cost))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BtRlGgqx9fV",
        "outputId": "6e084039-3d2a-4216-9350-28e409519ee7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1] Cost : 0.044940751045942307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트\n",
        "with torch.no_grad():\n",
        "  X = mnist_test.data.view(len(mnist_test), 1, 28, 28).float()\n",
        "  Y = mnist_test.targets\n",
        "\n",
        "  output = model(X)\n",
        "  prediction = torch.argmax(output, dim=1) == Y\n",
        "  correct_prediction = prediction.float().sum()\n",
        "\n",
        "print('정확도 : {}'.format(100 * correct_prediction / len(mnist_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xOlFwWu0lVS",
        "outputId": "cd8702f7-6304-4f25-e714-c01424c6c192"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도 : 98.58000183105469\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6YYdfohL1FFh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}