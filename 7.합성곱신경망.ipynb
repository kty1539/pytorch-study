{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 7-1 합성곱 신경망\n",
        "## 1. 합성곱 신경망의 대두\n",
        "- 합성곱 신경망은 이미지 처리에 탁월한 성능을 보이는 신경망이다.\n",
        "\n",
        "## 2. 채널\n",
        "- 기계는 글자나 이미지보다 숫자. 다시 말해, 텐서를 더 잘 처리할 수 있다.\n",
        "- 이미지는 (높이, 너비, 채널)이라는 3차원 텐서이다.\n",
        "  - 높이 : 이미지의 세로 방향 픽셀 수\n",
        "  - 너비 : 이미지의 가로 방향 픽셀 수\n",
        "  - 채널 : 색 성분\n",
        "- 흑백 이미지는 채널 수가 1이며, 각 픽셀은 0부터 255 사이의 값을 가진다. ex) (28 X 28 X 1)\n",
        "- 컬러 이미지는 적색, 녹색, 청색 채널 수가 3개이다.\n",
        "- 하나의 픽셀은 세 가지 색깔, 삼원색의 조합으로 이루어진다.\n",
        "- 만약, 높이가 28, 너비가 28인 컬러 이미지가 있다면 이 이미지의 텐서는 (28 X 28 X 3)의 크기를 가지는 3차원 텐서이다.\n",
        "- 채널은 때로는 깊이라고도 한다. (높이, 너비, 깊이)\n",
        "\n",
        "## 3. 합성곱 연산\n",
        "- 합성곱층은 합성곱 연산을 통해서 이미지의 특징을 추출하는 역할을 한다.\n",
        "- 합성곱은 영어로 컨볼루션이라고도 불리는데, 커널 또는 필터라는 **n x m** 크기의 행렬로 높이 x 너비 크기의 이미지를 처음부터 끝까지 겹치며 훑으면서 n x m크기의 겹쳐지는 부분의 각 이미지와 커널의 원소의 값을 곱해서 모두 더한 값을 출력하는 것을 말한다.\n",
        "  - 이미지의 가장 왼쪽 위부터 가장 오른쪽까지 순차적으로 훑는다.\n",
        "- 커널은 일반적으로 3 x 3 또는 5 x 5를 사용한다.\n",
        "- 커널을 사용하여 합성곱 연산을 통해 나온 결과를 특성맵이라고 한다.\n",
        "- 커널의 크기는 사용자가 정할 수 있으며 이동 범위(스트라이드) 또한 정할 수 있다.\n",
        "\n",
        "## 4. 패딩\n",
        "- 합성곱 연산의 결과로 얻은 특성 맵은 입력보다 크기가 작아진다는 특징이 있다.\n",
        "- 합성곱 층을 여러개 쌓았다면 최종적으로 얻은 특성맵은 초기 입력보다 매우 작아진 상태가 되버린다.\n",
        "- 따라서 합성곱 연산 이후에도 특성 맵의 크기가 입력의 크기와 동일하게 유지되도록 하고 싶다면 패딩을 사용하면 된다.\n",
        "- 패딩은 입력의 가장자리에 지정된 개수의 폭만큼 행과 열을 추가해주는 것을 말한다.\n",
        "- 주로 값을 0으로 채우는 제로 패딩을 사용한다.\n",
        "\n",
        "## 5. 가중치와 편향\n",
        "- 합성곱 신경망은 커널의 크기만큼의 가중치만 사용한다.\n",
        "- 합성곱 연산마다 이미지의 모든 픽셀을 사용하는 것이 아니라, 커널과 맵핑되는 픽셀만을 입력으로 사용한다.\n",
        "- 다층 퍼셉트론을 사용할 때보다 훨씬 적은 수의 가중치를 사용하며 공간적 구조 정보를 보존한다는 특징이 있다.\n",
        "- 합성곱 연산을 통해 얻은 특성 맵은 비선형성 추가를 위해서 활성화 함수를 지나게 되는데 이때 ReLU 함수나그 변형들이 주로 사용된다.\n",
        "- 합성곱 연산을 통해서 특성 맵을 얻고, 활성화 함수를 지나는 연산을 하는 합성곱 신경망의 은닉층을 합성곱 신경망에서는 합성곱 층이라고 한다.\n",
        "- 편향을 사용한다면 커널을 적용한 뒤에 더해진다.\n",
        "- 편향은 하나의 값만 존재하며, 커널이 적용된 결과의 모든 원소에 더해진다.\n",
        "\n",
        "## 6. 특성 맵의 크기 계산 방법\n",
        "- $I_h : 입력의 높이$\n",
        "- $I_w : 입력의 너비$\n",
        "- $K_h : 커널의 높이$\n",
        "- $K_w : 커널의 너비$\n",
        "- $S : 스트라이드$\n",
        "- $O_h : 특성 맵의 높이$\n",
        "- $O_w : 특성 맵의 너비$\n",
        "- $O_h = floor(\\frac{I_h - K_h}{S} + 1)$\n",
        "- $O_w = floor(\\frac{I_w - K_w}{S} + 1)$\n",
        "- floor 함수는 소수점 발생 시 소수점 이하를 버리는 역할을 한다.\n",
        "- 5 x 5 크기의 이미지에 3 x 3 커널을 사용하고 스트라이드 1로 합성곱 연산을 했을 경우 특성 맵의 크기는 (5-3+1) x (5-3+1) = 3 x 3임을 알 수 있다. 이는 또한 총 9번의 스텝이 필요함을 의미한다.\n",
        "- 패딩의 폭을 **P**라고 하고, 패딩까지 고려한 식은 아래와 같다.\n",
        "- $O_h = floor(\\frac{I_h - K_h + 2P}{S} + 1)$\n",
        "- $O_w = floor(\\frac{I_w - K_w + 2P}{S} + 1)$\n",
        "\n",
        "## 7. 다수의 채널을 가질 경우의 합성곱 연산\n",
        "- 다수의 채널을 가진 입력 데이터를 가지고 합성곱 연산을 한다고 하면 커널의 채널 수도 입력의 채널 수만큼 존재해야 한다.\n",
        "- 채널 수가 같으므로 합성곱 연산을 채널마다 수행하고 그 결과를 모두 더하여 최종 특성 맵을 얻는다.\n",
        "- 합성곱 연산의 결과로 얻은 특성 맵의 채널 차원은 RGB 채널 등과 같은 컬러의 의미를 담고 있지는 않는다.\n",
        "\n",
        "## 8. 3차원 텐서의 합성곱 연산\n",
        "- 하나의 입력에 여러 개의 커널을 사용하는 합성곱 연산을 할 수도 있다.\n",
        "- 합성곱 연산에서 다수의 커널을 사용할 경우, 사용한 커널 수는 합성곱 연산의 결과로 나오는 특성 맵의 채널 수가 된다.\n",
        "- 가중치 매개변수의 총 수 : $K_h × K_w × C_i × C_o$\n",
        "  - $K_h = 커널의 높이$\n",
        "  - $K_w = 커널의 너비$\n",
        "  - $C_i = 입력 데이터의 채널$\n",
        "  - $C_o = 커널의 수$\n",
        "\n",
        "## 9. 풀링\n",
        "- 일반적으로 합성곱 층(합성곱 연산+ 활성화 함수) 다음에는 풀링 층을 추가하는 것이 일반적이다.\n",
        "- 풀링 층에서는 특성 맵을 다운샘플링하여특성 맵의 크기를 줄이는 풀링 연산이 이루어진다.\n",
        "- 풀링 연산에는 최대 풀링과 평균 풀링이 사용된다.\n",
        "- 풀링 연산에서도 합성곱 연산과 마찬가지로 커널과 스트라이드의 개념을 가진다.\n",
        "- 맥스 풀링은 커널과 겹치는 영역 안에서 최대값을 추출하는 방식으로 다운샘플링한다.\n",
        "- 평균 풀링은 평균값을 추출한다.\n",
        "- 합성곱 연산과의 차이점은 학습해야 할 가중치가 없으며 연산 후에 채널 수가 변하지 않는다.\n"
      ],
      "metadata": {
        "id": "yyReF8GDRs43"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7-2 CNN으로 MNIST 분류하기\n",
        "## 1. 모델 이해하기\n",
        "- 1) 첫번째 표기 방법\n",
        "  - 합성곱(nn.Conv2d) + 활성화 함수(nn.ReLU)를 하나의 합성곱 층으로 보고, 맥스 풀링(nn.MaxPool2d)은 풀링 층으로 별도로 명명한다.\n",
        "- 2) 두번째 표기 방법\n",
        "  - 합성곱(nn.Conv2d) + 활성화 함수(nn.ReLU) + 맥스풀링(nn.MaxPool2d)을 하나의 합성곱 층으로 본다.\n",
        "- 누가 옳고 틀리냐의 문제는 아님\n",
        "- 모델의 아키텍처는총 3개의 층으로 구성된다.\n",
        "\n",
        "```\n",
        "# 1번 레이어 : 합성곱층(Convolutional layer)\n",
        "합성곱(in_channel = 1, out_channel = 32, kernel_size=3, stride=1, padding=1) + 활성화 함수 ReLU\n",
        "맥스풀링(kernel_size=2, stride=2)\n",
        "\n",
        "# 2번 레이어 : 합성곱층(Convolutional layer)\n",
        "합성곱(in_channel = 32, out_channel = 64, kernel_size=3, stride=1, padding=1) + 활성화 함수 ReLU\n",
        "\n",
        "# 3번 레이어 : 전결합층(Fully-Connected layer)\n",
        "특성맵을 펼친다. # batch_size x 7 x 7 x 64 -> batch_size x 3136\n",
        "전결합층(뉴런 10개) + 활성화 함수 Softmax\n",
        "```"
      ],
      "metadata": {
        "id": "TlMjVvLLaLyi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqCvTd0PRTNs",
        "outputId": "af112e67-ebe2-4eca-ff41-a7ba712fa121"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "텐서의 크기 : torch.Size([1, 1, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "# 모델 구현하기\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 배치 크기 x 채널 x 높이(height) x 너비(width)의 크기의 텐서를 선언\n",
        "inputs = torch.Tensor(1, 1, 28, 28)\n",
        "print('텐서의 크기 : {}'.format(inputs.shape))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 합성곱층과 풀링 선언하기\n",
        "conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "print(conv1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSif88_7b9Z_",
        "outputId": "ebf64b9c-bbf5-44e2-9cd9-f509253ba6d7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "print(conv2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-BFU1IhcG8O",
        "outputId": "35239ba0-7368-495e-d88d-9b393f98dce9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pool = nn.MaxPool2d(2)\n",
        "print(pool)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnbbgSBdcQJK",
        "outputId": "574ea3a9-1b47-44a2-9c13-ac015880d86d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 구현체를 연결하여 모델 만들기\n",
        "out = conv1(inputs)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdT6u65kcVDK",
        "outputId": "d796e5e1-1632-46de-d505-f15f17b04c40"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 32, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = pool(out)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljT5CubVcbCi",
        "outputId": "9519abd8-a96c-45de-d418-c0e06191543c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 32, 14, 14])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = conv2(out)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWVHg1wEckb7",
        "outputId": "b648545c-7dcb-4ca9-c982-1434e7e00fd1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 64, 14, 14])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = pool(out)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Oghtf8WcnEu",
        "outputId": "50328ff8-72d5-4681-e050-347f45ca7205"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 64, 7, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서의 n번째 차원의 크기\n",
        "print(out.size(0))\n",
        "print(out.size(1))\n",
        "print(out.size(2))\n",
        "print(out.size(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRVdCbYzcr1P",
        "outputId": "0b7e9969-3254-4cd2-8ee6-61d78d282574"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "64\n",
            "7\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫번째 차원인 배치 차원은 그대로 두고 나머지는 펼침\n",
        "out = out.view(out.size(0), -1)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18X-pQtkcxKJ",
        "outputId": "abb8babc-fda8-455f-b8f8-f1c9a0adfb6d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3136])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fc = nn.Linear(3136, 10)\n",
        "out = fc(out)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDgryzV-c_12",
        "outputId": "796d7975-1332-46bc-aec7-1e96378c0fda"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN으로 MNIST 분류하기\n",
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.init\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# 랜덤 시드 고정\n",
        "torch.manual_seed(777)\n",
        "\n",
        "if device == 'cuda':\n",
        "  torch.cuda.manual_seed_all(777)\n",
        "\n",
        "learning_rate = 0.001\n",
        "training_epochs = 15\n",
        "batch_size = 100\n",
        "\n",
        "# 데이터셋 정의\n",
        "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
        "                          train=True,\n",
        "                          transform=transforms.ToTensor(),\n",
        "                          download=True)\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
        "                         train=False,\n",
        "                         transform=transforms.ToTensor(),\n",
        "                         download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlPqp1EidOm5",
        "outputId": "b2a5c5d9-3e05-4cc7-f8f4-591acb90a647"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 20.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 613kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 5.66MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 2.40MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          drop_last=True)"
      ],
      "metadata": {
        "id": "YLrJNaovd4zV"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    # 첫번째 층\n",
        "    # ImgIn shape=(?, 28, 28, 1)\n",
        "    # Conv -> (?, 28, 28, 32)\n",
        "    # Pool -> (?, 14, 14, 32)\n",
        "    self.layer1 = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "    # 두번째 층\n",
        "    # ImgIn shape=(?, 14, 14, 32)\n",
        "    # Conv -> (?, 14, 14, 64)\n",
        "    # Pool -> (?, 7, 7, 64)\n",
        "    self.layer2 = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "    # 전결합층 7x7x64 inputs -> 10 outputs\n",
        "    self.fc = torch.nn.Linear(7 * 7 * 64, 10, bias=True)\n",
        "\n",
        "    # 전결합층 한정으로 가중치 초기화\n",
        "    torch.nn.init.xavier_uniform_(self.fc.weight)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.layer1(x)\n",
        "    out = self.layer2(out)\n",
        "    out = out.view(out.size(0), -1) # 전결합층을 위해서 Flatten\n",
        "    out = self.fc(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "bpDPT3GieDAG"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cnn 모델 정의\n",
        "model = CNN().to(device)\n",
        "\n",
        "# 비용함수와 옵티마이저 정의\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "total_batch = len(data_loader)\n",
        "print('총 배치의 수 : {}'.format(total_batch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ua2Xa-5Hf6r9",
        "outputId": "bc040cc1-4632-4369-ed07-046b17b82e34"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 배치의 수 : 600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(training_epochs):\n",
        "  avg_cost = 0 # 에포크당 평균 비용을 저장하기 위한 변수 초기화\n",
        "\n",
        "  for X, Y in data_loader:\n",
        "    # 이미지 데이터는 이미 (28 * 28) 크기를 가지므로, 별도의 reshape 필요 없음\n",
        "    X = X.to(device)\n",
        "    Y = Y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    hypothesis = model(X)\n",
        "    cost = criterion(hypothesis, Y)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    avg_cost += cost / total_batch\n",
        "\n",
        "  print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15YHP3zYgL57",
        "outputId": "f78ba175-e237-47d5-ea7a-17dafb327940"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch:    1] cost = 0.225560248\n",
            "[Epoch:    2] cost = 0.0630551875\n",
            "[Epoch:    3] cost = 0.0462681577\n",
            "[Epoch:    4] cost = 0.0374339223\n",
            "[Epoch:    5] cost = 0.0314037167\n",
            "[Epoch:    6] cost = 0.0261414386\n",
            "[Epoch:    7] cost = 0.0216277987\n",
            "[Epoch:    8] cost = 0.0179725569\n",
            "[Epoch:    9] cost = 0.0158094056\n",
            "[Epoch:   10] cost = 0.0131764095\n",
            "[Epoch:   11] cost = 0.00995210093\n",
            "[Epoch:   12] cost = 0.00957405847\n",
            "[Epoch:   13] cost = 0.00827191118\n",
            "[Epoch:   14] cost = 0.00659538386\n",
            "[Epoch:   15] cost = 0.00589284115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  # 테스트 데이터를 모델에 입력하기 위한 준비\n",
        "  X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
        "  Y_test = mnist_test.test_labels.to(device)\n",
        "  # 모델 예측 수행\n",
        "  prediction = model(X_test)\n",
        "  # 예측 결과와 실제 레이블 비교\n",
        "  correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
        "\n",
        "  # 정확도 계산\n",
        "  accuracy = correct_prediction.float().mean()\n",
        "\n",
        "  print('Accuracy:', accuracy.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWMPgEXMg1hL",
        "outputId": "6428bf26-dee1-4607-fc00-cad7255dab5c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/datasets/mnist.py:81: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/datasets/mnist.py:71: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9883999824523926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7-3 깊은 CNN으로 MNIST 분류하기"
      ],
      "metadata": {
        "id": "uFUaeTD6hsBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.init\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# 랜덤 시드 고정\n",
        "torch.manual_seed(777)\n",
        "\n",
        "if device == 'cuda':\n",
        "  torch.cuda.manual_seed_all(777)\n",
        "\n",
        "learning_rate = 0.001\n",
        "training_epochs = 15\n",
        "batch_size = 100\n",
        "\n",
        "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
        "                          train=True,\n",
        "                          transform=transforms.ToTensor(),\n",
        "                          download=True)\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
        "                         train=False,\n",
        "                         transform=transforms.ToTensor(),\n",
        "                         download=True)\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          drop_last=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irLeDWiKhvkA",
        "outputId": "f39fd6ca-c5ee-483d-9267-3ca953926d12"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 13.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 446kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.14MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 3.97MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    self.keep_prob = 0.5 # 드롭아웃 확률\n",
        "\n",
        "    # L1 = 첫 번째 합성곱층\n",
        "    # 입력 이미지 형태: (?, 28, 28, 1)\n",
        "    # Conv2d : 출력 채널 32개, 커널 크기 3x3, 스트라이드 1, 패딩 1\n",
        "    # ReLU: 활성화 함수\n",
        "    # MaxPool2d: 커널 크기 2x2, 스트라이드 2로 다운샘플링 -> 출력 형태: (?, 14, 14, 32)\n",
        "    self.layer1 = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "    # L2 = 두 번째 합성곱층\n",
        "    # 입력 이미지 형태: (?, 14, 14, 32)\n",
        "    # Conv2d: 출력 채널 64개, 커널 크기 3x3, 스트라이드 1, 패딩 1\n",
        "    # ReLU: 활성화 함수\n",
        "    # MaxPool2d: 커널 크기 2x2, 스트라이드 2로 다운샘플링 -> 출력 형태: (?, 7, 7, 64)\n",
        "    self.layer2 = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "    # L3 = 세 번째 합성곱층\n",
        "    # 입력 이미지 형태: (?, 7, 7, 64)\n",
        "    # Conv2d: 출력 채널 128개, 커널 크기 3x3, 스트라이드 1, 패딩 1\n",
        "    # ReLU: 활성화 함수\n",
        "    # MaxPool2d: 커널 크기 2x2, 스트라이드 2, 패딩 1로 다운샘플링 -> 출력 형태: (?, 4, 4, 128)\n",
        "    self.layer3 = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1))\n",
        "    # L4 = 첫 번째 선형층\n",
        "    # 입력 노드 수: 4x4x128,  출력 노드 수:625\n",
        "    # ReLU: 활성화 함수\n",
        "    # Dropout: 드롭아웃으로 과적합방지, p=0.5\n",
        "    self.fc1 = torch.nn.Linear(4 * 4 * 128, 625, bias=True)\n",
        "    torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
        "    self.layer4 = torch.nn.Sequential(\n",
        "        self.fc1,\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Dropout(p=1 - self.keep_prob)\n",
        "    )\n",
        "    # L5: 최종 선형층\n",
        "    # 입력 노드 수: 625, 출력 노드 수: 10\n",
        "    self.fc2 = torch.nn.Linear(625, 10, bias=True)\n",
        "    torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.layer1(x)\n",
        "    out = self.layer2(out)\n",
        "    out = self.layer3(out)\n",
        "    out = out.view(out.size(0), -1) # 선형층에 입력하기 위해 텐서를 Flatten\n",
        "    out = self.layer4(out)\n",
        "    out = self.fc2(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "W_zqlyQrib39"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN 모델 정의\n",
        "print(device)\n",
        "model = CNN().to(device)\n",
        "\n",
        "# 비용 함수와 옵티마이저 정의\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "total_batch = len(data_loader)\n",
        "print('총 배치의 수 : {}'.format(total_batch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mG_7Tdihk9hA",
        "outputId": "afa1ae2e-a06d-429f-d043-92ea58a9f2ee"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "총 배치의 수 : 600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(training_epochs):\n",
        "  avg_cost = 0\n",
        "\n",
        "  for X, Y in data_loader:\n",
        "    X = X.to(device)\n",
        "    Y = Y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    hypothesis = model(X)\n",
        "    cost = criterion(hypothesis, Y)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    avg_cost += cost / total_batch\n",
        "\n",
        "  print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7lpfcfsmK_L",
        "outputId": "53a76314-7798-41d6-ed64-a8c136f089c3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch:    1] cost = 0.191374063\n",
            "[Epoch:    2] cost = 0.0531995334\n",
            "[Epoch:    3] cost = 0.0364796519\n",
            "[Epoch:    4] cost = 0.0290255491\n",
            "[Epoch:    5] cost = 0.0236653835\n",
            "[Epoch:    6] cost = 0.0201793294\n",
            "[Epoch:    7] cost = 0.0174330603\n",
            "[Epoch:    8] cost = 0.0152056338\n",
            "[Epoch:    9] cost = 0.0132235996\n",
            "[Epoch:   10] cost = 0.010860526\n",
            "[Epoch:   11] cost = 0.0103050098\n",
            "[Epoch:   12] cost = 0.0103839943\n",
            "[Epoch:   13] cost = 0.00644465396\n",
            "[Epoch:   14] cost = 0.00735936733\n",
            "[Epoch:   15] cost = 0.00779714948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
        "  Y_test = mnist_test.test_labels.to(device)\n",
        "\n",
        "  prediction = model(X_test)\n",
        "  correct_prediction = torch.argmax(prediction, dim=1) == Y_test\n",
        "  accuracy = correct_prediction.float().mean()\n",
        "  print('Accuracy:', accuracy.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yLo-cmamj8u",
        "outputId": "9bf65815-3bbd-43f8-d916-b5e4e1ea2382"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9863999485969543\n"
          ]
        }
      ]
    }
  ]
}