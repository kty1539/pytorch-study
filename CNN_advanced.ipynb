{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Custom_DataLoader"
      ],
      "metadata": {
        "id": "egttwMKIHpGi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "L9YbsEk7FvxY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 설정\n",
        "batch_size = 2"
      ],
      "metadata": {
        "id": "NeLSDeAsH7Oh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지폴더 & 데이터로더\n",
        "img_dir = './images'\n",
        "img_data = dsets.ImageFolder(img_dir, transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "]))\n",
        "img_batch = data.DataLoader(img_data, batch_size=batch_size, shuffle=True, drop_last=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "vY3DvJKLIC5D",
        "outputId": "803da628-a104-481e-be69-186c257b848e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Found no valid file for the classes .ipynb_checkpoints. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-e937c3239c5f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 이미지폴더 & 데이터로더\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimg_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./images'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m img_data = dsets.ImageFolder(img_dir, transforms.Compose([\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomResizedCrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mallow_empty\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     ):\n\u001b[0;32m--> 328\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         samples = self.make_dataset(\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;31m# is potentially overridden and thus could have a different logic.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The class_to_idx parameter cannot be None.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         return make_dataset(\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_valid_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_empty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mextensions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"Supported extensions are: {extensions if isinstance(extensions, str) else ', '.join(extensions)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Found no valid file for the classes .ipynb_checkpoints. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGGNET"
      ],
      "metadata": {
        "id": "oKF00R-6MciW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torch.utils.data as data\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "F3f7BAOBKIVu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 설정\n",
        "batch_size = 1\n",
        "learning_rate = 0.0002\n",
        "epoch = 100"
      ],
      "metadata": {
        "id": "baINFST7Myzd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로더\n",
        "img_dir = './images'\n",
        "img_data = dsets.ImageFolder(img_dir, transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "]))\n",
        "img_batch = data.DataLoader(img_data, batch_size=batch_size, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "_hL3A9miM2Lr",
        "outputId": "d9c48751-146d-4ae1-dfaf-9791155b4052"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Found no valid file for the classes .ipynb_checkpoints. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-3e831e788493>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 데이터 로더\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimg_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./images'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m img_data = dsets.ImageFolder(img_dir, transforms.Compose([\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomResizedCrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mallow_empty\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     ):\n\u001b[0;32m--> 328\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         samples = self.make_dataset(\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;31m# is potentially overridden and thus could have a different logic.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The class_to_idx parameter cannot be None.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         return make_dataset(\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_valid_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_empty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mextensions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"Supported extensions are: {extensions if isinstance(extensions, str) else ', '.join(extensions)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Found no valid file for the classes .ipynb_checkpoints. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 정의\n",
        "# Basic Blocks\n",
        "def conv_2_block(in_dim, out_dim):\n",
        "  model = nn.Sequential(\n",
        "      nn.Conv2d(in_dim, out_dim, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2, 2)\n",
        "  )\n",
        "  return model\n",
        "\n",
        "def conv_3_block(in_dim, out_dim):\n",
        "  model = nn.Sequential(\n",
        "      nn.Conv2d(in_dim, out_dim, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2, 2)\n",
        "  )\n",
        "  return model"
      ],
      "metadata": {
        "id": "QsUvbe7lPZuI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG Model\n",
        "class VGG(nn.Module):\n",
        "  def __init__(self, base_dim, num_classes=2):\n",
        "    super(VGG, self).__init__()\n",
        "    self.feature = nn.Sequential(\n",
        "        conv_2_block(3, base_dim),\n",
        "        conv_2_block(base_dim, 2 * base_dim),\n",
        "        conv_3_block(2 * base_dim, 4 * base_dim),\n",
        "        conv_3_block(4 * base_dim, 8 * base_dim),\n",
        "        conv_3_block(8 * base_dim, 8 * base_dim),\n",
        "    )\n",
        "    self.fc_layer = nn.Sequential(\n",
        "        nn.Linear(8 * base_dim * 7 * 7, 100),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(),\n",
        "        nn.Linear(100, 20),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(),\n",
        "        nn.Linear(20, num_classes),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.feature(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.fc_layer(x)\n",
        "    return x\n",
        "\n",
        "model = VGG(base_dim=64).to(device)\n",
        "\n",
        "for i in model.named_children():\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuLNmZTRSdTp",
        "outputId": "890884b3-dd5a-4363-cfc4-b0cab8b480f2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('feature', Sequential(\n",
            "  (0): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (1): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (2): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): ReLU()\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (3): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): ReLU()\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (4): Sequential(\n",
            "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): ReLU()\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "))\n",
            "('fc_layer', Sequential(\n",
            "  (0): Linear(in_features=25088, out_features=100, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Dropout(p=0.5, inplace=False)\n",
            "  (3): Linear(in_features=100, out_features=20, bias=True)\n",
            "  (4): ReLU()\n",
            "  (5): Dropout(p=0.5, inplace=False)\n",
            "  (6): Linear(in_features=20, out_features=2, bias=True)\n",
            "))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer & loss\n",
        "loss_func = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "msyiLEnOTQ2A"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습\n",
        "for i in range(epoch):\n",
        "  for X, Y in img_batch:\n",
        "    X = X.to(device)\n",
        "    Y = Y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X)\n",
        "    loss = loss_func(output, Y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  if i % 10 == 0:\n",
        "    print(loss)"
      ],
      "metadata": {
        "id": "KiRHUXnQUE7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GoogleNet"
      ],
      "metadata": {
        "id": "dir15loPUc4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torch.utils.data as data\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "V8nE8KPsUZzX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터\n",
        "batch_size = 1\n",
        "learning_rate = 0.0002\n",
        "epoch = 100"
      ],
      "metadata": {
        "id": "E_x-DzzRVf4y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터로더\n",
        "img_dir = './images'\n",
        "img_data = dsets.ImageFolder(img_dir, transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "]))\n",
        "img_batch = data.DataLoader(img_data, batch_size=batch_size, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "NXrHAYTpVjpg",
        "outputId": "cb80a633-8c81-44fb-e140-9dbd665b33f2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Found no valid file for the classes .ipynb_checkpoints. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-f3e37751f779>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 데이터로더\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimg_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./images'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m img_data = dsets.ImageFolder(img_dir, transforms.Compose([\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomResizedCrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomHorizontalFlip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mallow_empty\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     ):\n\u001b[0;32m--> 328\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         samples = self.make_dataset(\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;31m# is potentially overridden and thus could have a different logic.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The class_to_idx parameter cannot be None.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         return make_dataset(\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_valid_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_empty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mextensions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"Supported extensions are: {extensions if isinstance(extensions, str) else ', '.join(extensions)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Found no valid file for the classes .ipynb_checkpoints. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델\n",
        "# Base module\n",
        "def conv_1(in_dim, out_dim):\n",
        "  model = nn.Sequential(\n",
        "      nn.Conv2d(in_dim, out_dim, 1, 1),\n",
        "      nn.ReLU(),\n",
        "  )\n",
        "  return model\n",
        "\n",
        "def conv_1_3(in_dim, mid_dim, out_dim):\n",
        "  model = nn.Sequential(\n",
        "      nn.Conv2d(in_dim, mid_dim, 1, 1),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(mid_dim, out_dim, 3, 1, 1),\n",
        "      nn.ReLU(),\n",
        "  )\n",
        "  return model\n",
        "\n",
        "def conv_1_5(in_dim, mid_dim, out_dim):\n",
        "  model = nn.Sequential(\n",
        "      nn.Conv2d(in_dim, mid_dim, 1, 1),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(mid_dim, out_dim, 5, 1, 2),\n",
        "      nn.ReLU(),\n",
        "  )\n",
        "  return model\n",
        "\n",
        "def max_3_1(in_dim, out_dim):\n",
        "  model = nn.Sequential(\n",
        "      nn.MaxPool2d(3, 1, 1),\n",
        "      nn.Conv2d(in_dim, out_dim, 1, 1),\n",
        "      nn.ReLU(),\n",
        "  )\n",
        "  return model"
      ],
      "metadata": {
        "id": "atzrVrCiWOM5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inception Module\n",
        "class inception_module(nn.Module):\n",
        "  def __init__(self, in_dim, out_dim_1, mid_dim_3, out_dim_3, mid_dim_5, out_dim_5, pool):\n",
        "    super(inception_module, self).__init__()\n",
        "\n",
        "    self.conv_1 = conv_1(in_dim, out_dim_1)\n",
        "    self.conv_1_3 = conv_1_3(in_dim, mid_dim_3, out_dim_3)\n",
        "    self.conv_1_5 = conv_1_5(in_dim, mid_dim_5, out_dim_5)\n",
        "    self.max_3_1 = max_3_1(in_dim, pool)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out_1 = self.conv_1(x)\n",
        "    out_2 = self.conv_1_3(x)\n",
        "    out_3 = self.conv_1_5(x)\n",
        "    out_4 = self.max_3_1(x)\n",
        "    output = torch.cat([out_1, out_2, out_3, out_4], 1)\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "NG6eMgHoXnH7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GoogLeNet\n",
        "class GoogLeNet(nn.Module):\n",
        "  def __init__(self, base_dim, num_classes=2):\n",
        "    super(GoogLeNet, self).__init__()\n",
        "    self.layer_1 = nn.Sequential(\n",
        "        nn.Conv2d(3, base_dim, 7, 2, 3),\n",
        "        nn.MaxPool2d(3, 2, 1),\n",
        "        nn.Conv2d(base_dim, base_dim*3, 3, 1, 1),\n",
        "        nn.MaxPool2d(3, 2, 1),\n",
        "    )\n",
        "    self.layer_2 = nn.Sequential(\n",
        "        inception_module(base_dim * 3, 64, 96, 128, 16, 32, 32),\n",
        "        inception_module(base_dim * 4, 128, 128, 192, 32, 96, 64),\n",
        "        nn.MaxPool2d(3, 2, 1),\n",
        "    )\n",
        "    self.layer_3 = nn.Sequential(\n",
        "        inception_module(480, 192, 96, 208, 16, 48, 64),\n",
        "        inception_module(512, 160, 112, 224, 24, 64, 64),\n",
        "        inception_module(512, 128, 128, 256, 24, 64, 64),\n",
        "        inception_module(512, 112, 144, 288, 32, 64, 64),\n",
        "        inception_module(528, 256, 160, 320, 32, 128, 128),\n",
        "        nn.MaxPool2d(3, 2, 1),\n",
        "    )\n",
        "    self.layer_4 = nn.Sequential(\n",
        "        inception_module(832, 256, 160, 320, 32, 128, 128),\n",
        "        inception_module(832, 384, 192, 384, 48, 128, 128),\n",
        "        nn.AvgPool2d(7, 1),\n",
        "    )\n",
        "    self.layer_5 = nn.Dropout2d(0.4)\n",
        "    self.fc_layer = nn.Linear(1024, 1000)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.layer_1(x)\n",
        "    out = self.layer_2(out)\n",
        "    out = self.layer_3(out)\n",
        "    out = self.layer_4(out)\n",
        "    out = self.layer_5(out)\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = self.fc_layer(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "model = GoogLeNet(base_dim=64).to(device)\n",
        "\n",
        "for i in model.named_children():\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqOFPus_aTRx",
        "outputId": "1e4282f7-71f8-49c8-c83b-864f3a32f84b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('layer_1', Sequential(\n",
            "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
            "  (1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (2): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "))\n",
            "('layer_2', Sequential(\n",
            "  (0): inception_module(\n",
            "    (conv_1): Sequential(\n",
            "      (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): ReLU()\n",
            "    )\n",
            "    (conv_1_3): Sequential(\n",
            "      (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (conv_1_5): Sequential(\n",
            "      (0): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (max_3_1): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "      (1): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (1): inception_module(\n",
            "    (conv_1): Sequential(\n",
            "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): ReLU()\n",
            "    )\n",
            "    (conv_1_3): Sequential(\n",
            "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (conv_1_5): Sequential(\n",
            "      (0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (max_3_1): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "      (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "))\n",
            "('layer_3', Sequential(\n",
            "  (0): inception_module(\n",
            "    (conv_1): Sequential(\n",
            "      (0): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): ReLU()\n",
            "    )\n",
            "    (conv_1_3): Sequential(\n",
            "      (0): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (conv_1_5): Sequential(\n",
            "      (0): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (max_3_1): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "      (1): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (1): inception_module(\n",
            "    (conv_1): Sequential(\n",
            "      (0): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): ReLU()\n",
            "    )\n",
            "    (conv_1_3): Sequential(\n",
            "      (0): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (conv_1_5): Sequential(\n",
            "      (0): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (max_3_1): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "      (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (2): inception_module(\n",
            "    (conv_1): Sequential(\n",
            "      (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): ReLU()\n",
            "    )\n",
            "    (conv_1_3): Sequential(\n",
            "      (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (conv_1_5): Sequential(\n",
            "      (0): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (max_3_1): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "      (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (3): inception_module(\n",
            "    (conv_1): Sequential(\n",
            "      (0): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): ReLU()\n",
            "    )\n",
            "    (conv_1_3): Sequential(\n",
            "      (0): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (conv_1_5): Sequential(\n",
            "      (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (max_3_1): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "      (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (4): inception_module(\n",
            "    (conv_1): Sequential(\n",
            "      (0): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): ReLU()\n",
            "    )\n",
            "    (conv_1_3): Sequential(\n",
            "      (0): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (conv_1_5): Sequential(\n",
            "      (0): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (max_3_1): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "      (1): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (5): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "))\n",
            "('layer_4', Sequential(\n",
            "  (0): inception_module(\n",
            "    (conv_1): Sequential(\n",
            "      (0): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): ReLU()\n",
            "    )\n",
            "    (conv_1_3): Sequential(\n",
            "      (0): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (conv_1_5): Sequential(\n",
            "      (0): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (max_3_1): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "      (1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (1): inception_module(\n",
            "    (conv_1): Sequential(\n",
            "      (0): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): ReLU()\n",
            "    )\n",
            "    (conv_1_3): Sequential(\n",
            "      (0): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (conv_1_5): Sequential(\n",
            "      (0): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (max_3_1): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "      (1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (2): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
            "))\n",
            "('layer_5', Dropout2d(p=0.4, inplace=False))\n",
            "('fc_layer', Linear(in_features=1024, out_features=1000, bias=True))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer & loss\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "UdW652L2kDWp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습\n",
        "for i in range(epoch):\n",
        "  for X, Y in img_batch:\n",
        "    X = X.to(device)\n",
        "    Y = Y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X)\n",
        "\n",
        "    loss = loss_func(output, Y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  if i % 10 == 0:\n",
        "    print(loss)"
      ],
      "metadata": {
        "id": "8v1nSUi4kr3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet"
      ],
      "metadata": {
        "id": "JUOC-JXNk6w1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torch.utils.data as data\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "TGSH9tAXk8bz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼 파라미터 설정\n",
        "batch_size = 1\n",
        "learning_rate = 0.0002\n",
        "epoch = 100"
      ],
      "metadata": {
        "id": "v0hMqE4-ll3Y"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터로더\n",
        "img_dir = './images'\n",
        "img_data = dsets.ImageFolder(img_dir, transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "]))\n",
        "\n",
        "img_batch = data.DataLoader(img_data, batch_size=batch_size, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "sUNLjmqRlo_7",
        "outputId": "2502c7c5-a001-4257-c03f-c9f9516c6d18"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './images'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ca8e3a004044>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 데이터로더\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimg_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./images'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m img_data = dsets.ImageFolder(img_dir, transforms.Compose([\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomResizedCrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mallow_empty\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     ):\n\u001b[0;32m--> 328\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    147\u001b[0m     ) -> None:\n\u001b[1;32m    148\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         samples = self.make_dataset(\n\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \"\"\"\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './images'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 정의\n",
        "# Basic Block\n",
        "def conv_block_1(in_dim, out_dim, act_fn):\n",
        "  model = nn.Sequential(\n",
        "      nn.Conv2d(in_dim, out_dim, kernel_size=1, stride=1),\n",
        "      act_fn,\n",
        "  )\n",
        "  return model\n",
        "\n",
        "def conv_block_1_stride_2(in_dim, out_dim, act_fn):\n",
        "  model = nn.Sequential(\n",
        "      nn.Conv2d(in_dim, out_dim, kernel_size=1, stride=2),\n",
        "      act_fn,\n",
        "  )\n",
        "  return model\n",
        "\n",
        "def conv_block_1_n(in_dim, out_dim):\n",
        "  model = nn.Sequential(\n",
        "      nn.Conv2d(in_dim, out_dim, kernel_size=1, stride=1),\n",
        "  )\n",
        "  return model\n",
        "\n",
        "def conv_block_1_stride_2_n(in_dim, out_dim):\n",
        "  model = nn.Sequential(\n",
        "      nn.Conv2d(in_dim, out_dim, kernel_size=1, stride=2),\n",
        "  )\n",
        "  return model\n",
        "\n",
        "def conv_block_3(in_dim, out_dim, act_fn):\n",
        "  model = nn.Sequential(\n",
        "      nn.Conv2d(in_dim, out_dim, kernel_size=3, stride=1, padding=1),\n",
        "      act_fn,\n",
        "  )\n",
        "  return model"
      ],
      "metadata": {
        "id": "6CYguWwGl-DN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bottle Neck Module\n",
        "class BottleNeck(nn.Module):\n",
        "  def __init__(self, in_dim, mid_dim, out_dim, act_fn):\n",
        "    super(BottleNeck, self).__init__()\n",
        "    self.layer = nn.Sequential(\n",
        "        conv_block_1(in_dim, mid_dim, act_fn),\n",
        "        conv_block_3(mid_dim, mid_dim, act_fn),\n",
        "        conv_block_1_n(mid_dim, out_dim),\n",
        "    )\n",
        "    self.downsample = nn.Conv2d(in_dim, out_dim, 1, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    downsample = self.downsample(x)\n",
        "    out = self.layer(x)\n",
        "    out = out + downsample\n",
        "\n",
        "    return out\n",
        "\n",
        "class BottleNeck_no_down(nn.Module):\n",
        "  def __init__(self, in_dim, mid_dim, out_dim, act_fn):\n",
        "    super(BottleNeck_no_down, self).__init__()\n",
        "    self.layer = nn.Sequential(\n",
        "        conv_block_1(in_dim, mid_dim, act_fn),\n",
        "        conv_block_3(mid_dim, mid_dim, act_fn),\n",
        "        conv_block_1_n(mid_dim, out_dim),\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    out = self.layer(x)\n",
        "    out = out + x\n",
        "\n",
        "    return out\n",
        "\n",
        "class BottleNeck_stride(nn.Module):\n",
        "  def __init__(self, in_dim, mid_dim, out_dim, act_fn):\n",
        "    super(BottleNeck_stride, self).__init__()\n",
        "    self.layer = nn.Sequential(\n",
        "        conv_block_1_stride_2(in_dim, mid_dim, act_fn),\n",
        "        conv_block_3(mid_dim, mid_dim, act_fn),\n",
        "        conv_block_1_n(mid_dim, out_dim),\n",
        "    )\n",
        "    self.downsample = nn.Conv2d(in_dim, out_dim, 1, 2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    downsample = self.downsample(x)\n",
        "    out = self.layer(x)\n",
        "    out = out + downsample\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "lqXjajC4muY5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet Model\n",
        "class ResNet(nn.Module):\n",
        "  def __init__(self, base_dim, num_classes=2):\n",
        "    super(ResNet, self).__init__()\n",
        "    self.act_fn = nn.ReLU()\n",
        "    self.layer_1 = nn.Sequential(\n",
        "        nn.Conv2d(3, base_dim, 7, 2, 3),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(3, 2, 1),\n",
        "    )\n",
        "    self.layer_2 = nn.Sequential(\n",
        "        BottleNeck(base_dim, base_dim, base_dim * 4, self.act_fn),\n",
        "        BottleNeck_no_down(base_dim * 4, base_dim, base_dim * 4, self.act_fn),\n",
        "        BottleNeck_stride(base_dim * 4, base_dim, base_dim * 4, self.act_fn),\n",
        "    )\n",
        "    self.layer_3 = nn.Sequential(\n",
        "        BottleNeck(base_dim * 4, base_dim * 2, base_dim * 8, self.act_fn),\n",
        "        BottleNeck_no_down(base_dim * 8, base_dim * 2, base_dim * 8, self.act_fn),\n",
        "        BottleNeck_no_down(base_dim * 8, base_dim * 2, base_dim * 8, self.act_fn),\n",
        "        BottleNeck_stride(base_dim * 8, base_dim * 2, base_dim * 8, self.act_fn),\n",
        "    )\n",
        "    self.layer_4 = nn.Sequential(\n",
        "        BottleNeck(base_dim * 8, base_dim * 4, base_dim * 16, self.act_fn),\n",
        "        BottleNeck_no_down(base_dim * 16, base_dim * 4, base_dim * 16, self.act_fn),\n",
        "        BottleNeck_no_down(base_dim * 16, base_dim * 4, base_dim * 16, self.act_fn),\n",
        "        BottleNeck_no_down(base_dim * 16, base_dim * 4, base_dim * 16, self.act_fn),\n",
        "        BottleNeck_no_down(base_dim * 16, base_dim * 4, base_dim * 16, self.act_fn),\n",
        "        BottleNeck_stride(base_dim * 16, base_dim * 4, base_dim * 16, self.act_fn),\n",
        "    )\n",
        "    self.layer_5 = nn.Sequential(\n",
        "        BottleNeck(base_dim * 16, base_dim * 8, base_dim * 32, nn.ReLU()),\n",
        "        BottleNeck_no_down(base_dim * 32, base_dim * 8, base_dim * 32, self.act_fn),\n",
        "        BottleNeck(base_dim * 32, base_dim * 8, base_dim * 32, self.act_fn),\n",
        "    )\n",
        "    self.avgpool = nn.AvgPool2d(7, 1)\n",
        "    self.fc_layer = nn.Linear(base_dim * 32, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.layer_1(x)\n",
        "    out = self.layer_2(out)\n",
        "    out = self.layer_3(out)\n",
        "    out = self.layer_4(out)\n",
        "    out = self.layer_5(out)\n",
        "    out = self.avgpool(out)\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = self.fc_layer(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "model = ResNet(base_dim=64).to(device)\n",
        "\n",
        "for i in model.named_children():\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jdwa-Qdon-kJ",
        "outputId": "5a547077-1bdc-40cf-90ca-0f8219de8e0c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('act_fn', ReLU())\n",
            "('layer_1', Sequential(\n",
            "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
            "  (1): ReLU()\n",
            "  (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "))\n",
            "('layer_2', Sequential(\n",
            "  (0): BottleNeck(\n",
            "    (layer): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "    )\n",
            "    (downsample): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (1): BottleNeck_no_down(\n",
            "    (layer): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (2): BottleNeck_stride(\n",
            "    (layer): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(2, 2))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "    )\n",
            "    (downsample): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2))\n",
            "  )\n",
            "))\n",
            "('layer_3', Sequential(\n",
            "  (0): BottleNeck(\n",
            "    (layer): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "    )\n",
            "    (downsample): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (1): BottleNeck_no_down(\n",
            "    (layer): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (2): BottleNeck_no_down(\n",
            "    (layer): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (3): BottleNeck_stride(\n",
            "    (layer): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(2, 2))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "    )\n",
            "    (downsample): Conv2d(512, 512, kernel_size=(1, 1), stride=(2, 2))\n",
            "  )\n",
            "))\n",
            "('layer_4', Sequential(\n",
            "  (0): BottleNeck(\n",
            "    (layer): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "    )\n",
            "    (downsample): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (1): BottleNeck_no_down(\n",
            "    (layer): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (2): BottleNeck_no_down(\n",
            "    (layer): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (3): BottleNeck_no_down(\n",
            "    (layer): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (4): BottleNeck_no_down(\n",
            "    (layer): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (5): BottleNeck_stride(\n",
            "    (layer): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(2, 2))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "    )\n",
            "    (downsample): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
            "  )\n",
            "))\n",
            "('layer_5', Sequential(\n",
            "  (0): BottleNeck(\n",
            "    (layer): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "    )\n",
            "    (downsample): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (1): BottleNeck_no_down(\n",
            "    (layer): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (2): BottleNeck(\n",
            "    (layer): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "    )\n",
            "    (downsample): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "))\n",
            "('avgpool', AvgPool2d(kernel_size=7, stride=1, padding=0))\n",
            "('fc_layer', Linear(in_features=2048, out_features=2, bias=True))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer & loss\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "s7kF3Eq7q3_R"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습\n",
        "for i in range(epoch):\n",
        "  for X, Y in img_batch:\n",
        "    X = X.to(device)\n",
        "    Y = Y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X)\n",
        "    loss = loss_func(output, Y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  if i % 10 == 0:\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "eVWnQ-3irFZ5",
        "outputId": "35d047c0-a212-4b60-bed4-b4a5d809bd08"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'img_batch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-46d46af523c0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'img_batch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nc6x6CIGrT_A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}